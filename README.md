# Text-Analysis

# Introduction to Text Analysis using Python
##
##
### Regex patterns
### ________________________________________________________

import re

my_string = "Introduction to Text Analysis using Python"

re.findall(r"\s+", my_string)

re.findall(r"\w+", my_string)

re.findall(r"[a-z]", my_string)

re.findall(r"\w", my_string)

### ________________________________________________________

### Word tokenization 

The NLTK library can provide us a way to tokenize both words and sentences from Python strings.  we can use **word_tokenize** and **sent_tokenize** from **nltk.tokenize**. 

Running topic modeling using R and . 
It has focused on LDA.  
